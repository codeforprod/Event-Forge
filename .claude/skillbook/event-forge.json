{
  "version": "1.1.0",
  "service": "event-forge",
  "description": "Skillbook for Event-Forge project - patterns, learnings, and best practices",
  "skills": [
    {
      "id": "changesets-monorepo-setup",
      "category": "best-practices",
      "title": "Setting up Changesets for monorepo package publishing",
      "problem": "Need automated version management and publishing for multiple NPM packages in a monorepo",
      "solution": "Use Changesets with linked configuration to synchronize versions across all packages",
      "implementation": {
        "steps": [
          "Install @changesets/cli as dev dependency",
          "Run 'pnpm changeset init' to create .changeset directory",
          "Configure .changeset/config.json with 'linked' array containing package patterns",
          "Set 'access' to 'public' for NPM publishing",
          "Add scripts: changeset, version-packages, ci:publish, release"
        ],
        "config_example": {
          "linked": [["@event-forge/inbox-outbox-*"]],
          "access": "public",
          "baseBranch": "main"
        }
      },
      "benefits": [
        "Decouples versioning from git commits",
        "Auto-generates CHANGELOG",
        "Creates version bump PRs automatically",
        "Handles monorepo inter-package dependencies"
      ],
      "tags": ["changesets", "monorepo", "publishing", "npm", "versioning"]
    },
    {
      "id": "pypi-trusted-publishers",
      "category": "best-practices",
      "title": "Using PyPI Trusted Publishers for secure publishing",
      "problem": "Need secure PyPI publishing without manual API tokens",
      "solution": "Use PyPI Trusted Publishers with GitHub Actions OIDC",
      "implementation": {
        "steps": [
          "Configure PyPI project with Trusted Publisher settings (owner, repo, workflow, environment)",
          "Use pypa/gh-action-pypi-publish@release/v1 action",
          "Set permissions: id-token: write, contents: read",
          "Use GitHub environment 'pypi' for protection",
          "Enable attestations: true for PEP 740 compliance"
        ],
        "github_workflow": {
          "environment": {
            "name": "pypi",
            "url": "https://pypi.org/p/{package-name}"
          },
          "permissions": {
            "id-token": "write",
            "contents": "read"
          }
        }
      },
      "benefits": [
        "No manual API tokens to manage",
        "Automatic package attestations (PEP 740)",
        "More secure than token-based auth",
        "Integrated with GitHub Actions"
      ],
      "tags": ["pypi", "publishing", "security", "oidc", "trusted-publishers"]
    },
    {
      "id": "npm-python-version-sync",
      "category": "automation",
      "title": "Synchronizing NPM and Python package versions",
      "problem": "Monorepo with both NPM and Python packages needs synchronized versions",
      "solution": "Create sync script that updates Python pyproject.toml from NPM package.json",
      "implementation": {
        "script": "scripts/sync-python-version.js",
        "approach": "Read version from packages/core/package.json, update pyproject.toml using regex replacement",
        "integration": "Run as GitHub Actions step before publishing Python package",
        "script_example": "fs.readFileSync + regex replace /^version\\s*=\\s*\"[^\"]*\"/m"
      },
      "benefits": [
        "Single source of truth for versions (NPM core package)",
        "Automated - no manual version updates needed",
        "Runs in CI pipeline before publishing"
      ],
      "tags": ["version-sync", "npm", "python", "automation", "monorepo"]
    },
    {
      "id": "changesets-github-actions-workflow",
      "category": "ci-cd",
      "title": "Implementing Changesets with GitHub Actions",
      "problem": "Need automated workflow to create version PRs and publish packages",
      "solution": "Use changesets/action@v1 in GitHub Actions workflow",
      "implementation": {
        "workflow_structure": {
          "trigger": "push to main branch",
          "concurrency": "prevent parallel executions",
          "job_outputs": "published, publishedPackages for conditional downstream jobs",
          "steps": [
            "Checkout with fetch-depth: 0",
            "Setup pnpm and Node.js",
            "Build and test",
            "Run changesets action with publish command"
          ]
        },
        "changesets_action_config": {
          "commit": "chore(release): version packages",
          "title": "chore(release): version packages",
          "publish": "pnpm ci:publish"
        }
      },
      "workflow": [
        "Developer creates changeset locally",
        "Changes merged to main",
        "Workflow creates 'Version Packages' PR (if changesets exist)",
        "Merging version PR triggers publish job",
        "Published packages trigger downstream jobs (e.g., Python publishing)"
      ],
      "tags": ["changesets", "github-actions", "ci-cd", "automation", "publishing"]
    },
    {
      "id": "conditional-pypi-publishing",
      "category": "ci-cd",
      "title": "Conditional PyPI publishing based on NPM release",
      "problem": "Python package should only publish when NPM packages are published",
      "solution": "Use job outputs and conditional execution in GitHub Actions",
      "implementation": {
        "pattern": "needs: release, if: needs.release.outputs.published == 'true'",
        "job_outputs": "Set outputs in NPM job from changesets action",
        "conditional_job": "PyPI job depends on NPM job and checks published output"
      },
      "benefits": [
        "Prevents unnecessary PyPI publishes",
        "Ensures version synchronization",
        "Cleaner workflow execution"
      ],
      "tags": ["github-actions", "conditional-execution", "pypi", "npm", "workflow"]
    },
    {
      "id": "typeorm-pessimistic-lock-transaction",
      "category": "bug-patterns",
      "title": "TypeORM pessimistic locks must be wrapped in transactions",
      "problem": "PessimisticLockTransactionRequiredError when using setLock('pessimistic_write')",
      "symptoms": [
        "Error: 'An optimistic lock can only be used inside a transaction'",
        "Method using pessimistic_write lock fails at runtime",
        "Query builder with FOR UPDATE SKIP LOCKED throws error"
      ],
      "root_cause": "TypeORM requires pessimistic locks (FOR UPDATE) to be executed within an active transaction context",
      "investigation": [
        "Check if query builder uses setLock('pessimistic_write') or setLock('pessimistic_read')",
        "Verify if the operation is wrapped in dataSource.transaction()",
        "Examine if operations use this.repository vs manager.getRepository()"
      ],
      "solution": {
        "pattern": "Wrap entire method in dataSource.transaction() and use manager.getRepository()",
        "before": "async fetchAndLock() { const query = this.repository.createQueryBuilder().setLock('pessimistic_write'); }",
        "after": "async fetchAndLock() { return this.dataSource.transaction(async (manager) => { const query = manager.getRepository(Entity).createQueryBuilder().setLock('pessimistic_write'); }); }",
        "key_changes": [
          "Wrap in this.dataSource.transaction(async (manager) => {...})",
          "Replace this.repository with manager.getRepository(EntityClass)",
          "All operations in method must use manager.getRepository()",
          "Return value from transaction callback"
        ]
      },
      "prevention": [
        "Always use pessimistic locks within transaction boundaries",
        "Code review checklist: setLock() calls must be inside transaction()",
        "Add integration tests for concurrent lock scenarios",
        "Document transaction requirements in method comments"
      ],
      "related_patterns": [
        "SKIP LOCKED for non-blocking concurrent processing",
        "Atomic status updates within same transaction as lock",
        "Manager pattern for transactional repositories"
      ],
      "example": {
        "file": "packages/adapter-typeorm/src/repositories/typeorm-outbox.repository.ts",
        "method": "fetchAndLockPending",
        "fix_commit": "AIRIS-46"
      },
      "tags": ["typeorm", "pessimistic-lock", "transaction", "postgresql", "concurrency", "bug-fix"]
    },
    {
      "id": "nestjs-lifecycle-hooks",
      "category": "best-practices",
      "title": "Automatic service lifecycle management in NestJS modules",
      "problem": "Consumers must manually start/stop polling in their own lifecycle hooks, leading to boilerplate code",
      "solution": "Create a lifecycle service implementing OnApplicationBootstrap and OnApplicationShutdown that automatically manages service lifecycle",
      "implementation": {
        "steps": [
          "Create service implementing OnApplicationBootstrap and OnApplicationShutdown",
          "Inject the service to manage (e.g., OutboxService)",
          "Call service methods in lifecycle hooks",
          "Add lifecycle.autoStart configuration option (default: true)",
          "Conditionally provide lifecycle service based on configuration",
          "Export lifecycle service for manual control if needed"
        ],
        "code_example": {
          "service": "@Injectable() class EventForgeLifecycleService { constructor(@Inject(TOKEN) private service) {} onApplicationBootstrap() { this.service.start(); } onApplicationShutdown() { this.service.stop(); } }",
          "conditional_provider": "if (options.lifecycle?.autoStart !== false) { providers.push(LifecycleService); }",
          "config": "{ lifecycle: { autoStart: true } }"
        }
      },
      "benefits": [
        "Eliminates boilerplate lifecycle code in consumer applications",
        "Ensures consistent lifecycle management",
        "Graceful shutdown handling",
        "Optional - can be disabled for custom control"
      ],
      "tags": ["nestjs", "lifecycle", "automation", "di", "best-practice"]
    },
    {
      "id": "nestjs-conditional-providers",
      "category": "best-practices",
      "title": "Conditional provider registration based on configuration",
      "problem": "Need to conditionally provide services based on user configuration options",
      "solution": "Use factory providers that check configuration and return null when service should not be provided",
      "implementation": {
        "pattern": "useFactory with conditional logic",
        "code_example": "{ provide: Service, useFactory: (config) => config.enabled !== false ? new Service() : null, inject: [CONFIG] }",
        "null_safe_default": "Use !== false instead of === true to default to true (treats undefined/null as true)"
      },
      "benefits": [
        "Clean DI without complex conditional module registration",
        "Type-safe configuration",
        "Easy to test with different configurations"
      ],
      "tags": ["nestjs", "di", "conditional-logic", "configuration"]
    },
    {
      "id": "eslint-import-order",
      "category": "code-quality",
      "title": "ESLint import/order rule compliance",
      "problem": "ESLint import/order errors: 'There should be at least one empty line between import groups'",
      "solution": "Add empty line between external package imports and internal (relative) imports",
      "implementation": {
        "correct_pattern": "import { External } from '@package';\nimport { External2 } from '@package2';\n\nimport { Internal } from './internal';",
        "groups": "1. External packages (@namespace, npm packages), 2. Empty line, 3. Internal imports (./relative)"
      },
      "tags": ["eslint", "import-order", "code-style", "linting"]
    },
    {
      "id": "rabbitmq-x-delay-header-mapping",
      "category": "best-practices",
      "title": "Mapping metadata.delay to x-delay header for RabbitMQ delayed messages",
      "problem": "Need to map application-level delay metadata to RabbitMQ-specific x-delay header",
      "solution": "Extract and validate metadata.delay field, then map to x-delay header only for valid delays",
      "implementation": {
        "validation_rules": [
          "Must be a number type",
          "Must be >= 0 (non-negative)",
          "Reject: string, null, undefined, NaN, object, negative numbers",
          "Accept: positive numbers, zero (treated as immediate), Infinity"
        ],
        "extraction_pattern": "Check existence → type check → range check → return number or null",
        "header_mapping": "Only add x-delay header if delay is valid number >= 0"
      },
      "benefits": [
        "Type-safe delay handling",
        "Graceful degradation to immediate delivery on invalid input",
        "Clear separation between metadata (application) and headers (broker)",
        "Prevents runtime errors from invalid delay values"
      ],
      "code_example": "private extractDelay(message: OutboxMessage): number | null {\n  if (!message.metadata?.delay) return null;\n  const delay = message.metadata.delay;\n  if (typeof delay !== 'number') return null;\n  if (delay < 0) return null;\n  return delay;\n}",
      "tags": ["rabbitmq", "validation", "type-safety", "header-mapping", "delayed-messages"]
    },
    {
      "id": "comprehensive-edge-case-testing",
      "category": "testing",
      "title": "Testing edge cases for optional numeric fields with fallback behavior",
      "problem": "Need to ensure robust handling of invalid input for optional numeric configuration fields",
      "solution": "Create comprehensive test suite covering all invalid value types and edge cases",
      "implementation": {
        "test_categories": [
          "Type mismatches (string, object, null, undefined)",
          "Special numeric values (NaN, Infinity, -Infinity)",
          "Range violations (negative numbers, zero)",
          "Valid values (positive numbers, large numbers)"
        ],
        "test_pattern": "Arrange → Act → Assert fallback behavior",
        "coverage_targets": [
          "Test 8+ invalid value scenarios",
          "Verify graceful fallback for each",
          "Ensure no exceptions thrown",
          "Validate correct behavior for valid values"
        ]
      },
      "benefits": [
        "Prevents production failures from unexpected input",
        "Documents expected behavior through tests",
        "Catches regressions during refactoring",
        "Builds confidence in error handling"
      ],
      "edge_cases_tested": [
        "negative delay → immediate delivery",
        "string delay → immediate delivery",
        "null delay → immediate delivery",
        "undefined delay → immediate delivery",
        "NaN delay → immediate delivery",
        "object delay → immediate delivery",
        "zero delay → immediate delivery",
        "Infinity delay → delayed delivery (valid)"
      ],
      "tags": ["testing", "edge-cases", "validation", "robustness", "type-safety"]
    },
    {
      "id": "plugin-prerequisite-documentation",
      "category": "documentation",
      "title": "Documenting external plugin dependencies in library READMEs",
      "problem": "Library features depend on external RabbitMQ plugins that must be installed separately",
      "solution": "Create dedicated Prerequisites section with installation commands and configuration examples",
      "implementation": {
        "structure": [
          "Prerequisites heading before Usage section",
          "Clear statement of requirement (what plugin, why needed)",
          "Installation commands (bash examples)",
          "Configuration examples (exchange setup)",
          "Link to official plugin documentation"
        ],
        "content_elements": [
          "Command-line installation (rabbitmq-plugins enable)",
          "Server restart instructions",
          "Exchange configuration (rabbitmqadmin or programmatic)",
          "Error handling guidance (what happens if plugin missing)"
        ]
      },
      "benefits": [
        "Prevents user confusion and support requests",
        "Clear setup path for new users",
        "Reduces integration time",
        "Sets correct expectations about external dependencies"
      ],
      "example_structure": "## Prerequisites\n\nRequires rabbitmq_delayed_message_exchange plugin.\n\n**Installation:**\n```bash\nrabbitmq-plugins enable rabbitmq_delayed_message_exchange\nrabbitmqctl restart\n```\n\n**Exchange Configuration:**\n```bash\nrabbitmqadmin declare exchange name=events.delayed type=x-delayed-message\n```",
      "tags": ["documentation", "prerequisites", "dependencies", "user-guidance", "rabbitmq"]
    }
  ],
  "patterns": [
    {
      "id": "monorepo-publishing-architecture",
      "category": "architecture",
      "name": "Monorepo multi-platform publishing architecture",
      "context": "Publishing packages to multiple registries (NPM + PyPI) from single monorepo",
      "pattern": "Use Changesets for NPM version management, sync script for Python versions, GitHub Actions for automation",
      "components": [
        "Changesets - NPM version management and changelog",
        "Version sync script - Synchronize NPM to Python",
        "GitHub Actions workflows - Automation (release.yml for publishing, ci.yml for validation)",
        "Trusted Publishers - Secure PyPI publishing without tokens"
      ],
      "trade_offs": {
        "pros": [
          "Single source of truth for versions",
          "Automated version bumps and publishing",
          "Secure (no manual tokens for PyPI)",
          "Clear developer workflow"
        ],
        "cons": [
          "Requires external setup (NPM token, PyPI trusted publisher config)",
          "Learning curve for Changesets workflow",
          "Two-step process (version PR, then publish)"
        ]
      },
      "when_to_use": "Multi-platform monorepos with frequent releases",
      "when_to_avoid": "Single package projects or infrequent manual releases"
    },
    {
      "id": "nestjs-lifecycle-automation",
      "category": "architecture",
      "name": "Automatic lifecycle management in NestJS libraries",
      "context": "Building NestJS libraries that manage background services requiring start/stop",
      "pattern": "Provide optional lifecycle service that automatically manages service lifecycle via NestJS hooks",
      "components": [
        "Lifecycle service implementing OnApplicationBootstrap and OnApplicationShutdown",
        "Configuration option (lifecycle.autoStart) to enable/disable automatic management",
        "Conditional provider registration based on configuration",
        "Service export for manual control when autoStart is disabled"
      ],
      "trade_offs": {
        "pros": [
          "Zero boilerplate for consumers (works out of the box)",
          "Consistent lifecycle management",
          "Graceful shutdown handling",
          "Optional - can be disabled for custom control"
        ],
        "cons": [
          "Adds complexity to module registration logic",
          "Less explicit control (hidden lifecycle management)",
          "Requires understanding of conditional providers"
        ]
      },
      "when_to_use": "Libraries managing background services (polling, scheduled tasks, connections)",
      "when_to_avoid": "Simple libraries without lifecycle needs or stateless utilities"
    },
    {
      "id": "dual-exchange-delayed-messages",
      "category": "architecture",
      "name": "Dual exchange pattern for delayed message delivery",
      "context": "Message publisher needs to support both immediate and delayed delivery without performance penalty",
      "pattern": "Use two separate exchanges (direct + delayed) with automatic selection based on message metadata",
      "components": [
        "Direct exchange - Handles immediate messages (standard topic exchange)",
        "Delayed exchange - Handles delayed messages (x-delayed-message type)",
        "Selection logic - Routes to appropriate exchange based on metadata.delay presence",
        "Header mapping - Converts metadata.delay to x-delay header for delayed exchange"
      ],
      "implementation_details": {
        "routing_logic": "if (delay !== null) use delayedExchange else use directExchange",
        "header_transformation": "metadata.delay (milliseconds) → x-delay header (milliseconds)",
        "routing_key_format": "{aggregateType}.{eventType}"
      },
      "trade_offs": {
        "pros": [
          "No delay overhead for immediate messages",
          "Clear separation of concerns (immediate vs delayed)",
          "Can monitor each exchange independently",
          "Delayed exchange failure doesn't affect immediate delivery"
        ],
        "cons": [
          "Requires two exchange configurations",
          "Requires rabbitmq_delayed_message_exchange plugin",
          "More complex RabbitMQ topology"
        ]
      },
      "when_to_use": [
        "Mix of immediate and delayed messages in same system",
        "High-volume immediate messages with occasional delayed ones",
        "Need separate monitoring/metrics for immediate vs delayed"
      ],
      "when_to_avoid": [
        "Only delayed messages (single delayed exchange sufficient)",
        "Cannot install RabbitMQ plugins",
        "Simple pub-sub without delay requirements"
      ],
      "related_patterns": ["single-exchange-with-ttl", "queue-level-delays"]
    }
  ],
  "anti_patterns": [
    {
      "id": "manual-version-updates",
      "name": "Manual version updates in monorepos",
      "problem": "Manually updating version numbers in multiple package.json files",
      "why_bad": [
        "Error-prone (easy to miss packages)",
        "Time-consuming",
        "No automatic changelog",
        "Inter-package dependency versions can get out of sync"
      ],
      "better_approach": "Use Changesets with linked configuration for automatic version management",
      "tags": ["versioning", "monorepo", "manual-work"]
    },
    {
      "id": "pypi-api-tokens-in-ci",
      "name": "Using PyPI API tokens in GitHub Actions",
      "problem": "Storing PyPI API tokens as GitHub secrets",
      "why_bad": [
        "Security risk (tokens can leak)",
        "Manual token rotation required",
        "No automatic package attestations",
        "Less secure than OIDC"
      ],
      "better_approach": "Use PyPI Trusted Publishers with GitHub Actions OIDC",
      "tags": ["security", "pypi", "tokens", "oidc"]
    },
    {
      "id": "pessimistic-lock-without-transaction",
      "name": "Using pessimistic locks outside transactions in TypeORM",
      "problem": "Calling setLock('pessimistic_write') on query builder without wrapping in transaction",
      "why_bad": [
        "Throws PessimisticLockTransactionRequiredError at runtime",
        "Violates TypeORM's transaction requirements",
        "Can lead to race conditions if not properly handled",
        "Tests may pass but production fails"
      ],
      "better_approach": "Always wrap pessimistic lock operations in dataSource.transaction()",
      "example": {
        "wrong": "this.repository.createQueryBuilder().setLock('pessimistic_write').getMany()",
        "correct": "this.dataSource.transaction(async (manager) => manager.getRepository(Entity).createQueryBuilder().setLock('pessimistic_write').getMany())"
      },
      "tags": ["typeorm", "pessimistic-lock", "transaction", "anti-pattern"]
    },
    {
      "id": "manual-lifecycle-in-consumers",
      "name": "Requiring consumers to manually manage service lifecycle",
      "problem": "NestJS library requires every consumer to add onApplicationBootstrap/onApplicationShutdown hooks",
      "why_bad": [
        "Boilerplate code in every consumer",
        "Easy to forget, leading to resource leaks",
        "Inconsistent implementation across consumers",
        "Poor developer experience"
      ],
      "better_approach": "Provide automatic lifecycle management with opt-out configuration",
      "example": {
        "bad": "Consumer must: constructor(service) {} onApplicationBootstrap() { service.start(); }",
        "good": "Library handles automatically via lifecycle service"
      },
      "tags": ["nestjs", "lifecycle", "dx", "boilerplate"]
    },
    {
      "id": "single-exchange-for-all-messages",
      "name": "Using single exchange for both immediate and delayed messages",
      "problem": "Routing all messages (immediate and delayed) through x-delayed-message exchange",
      "why_bad": [
        "Performance overhead: All messages go through delay plugin even if delay=0",
        "Cannot monitor immediate vs delayed separately",
        "Plugin failure affects all message delivery",
        "Wastes resources checking delay for immediate messages"
      ],
      "better_approach": "Use dual exchange pattern: direct exchange for immediate, delayed exchange for delayed messages",
      "tags": ["rabbitmq", "performance", "architecture", "delayed-messages"]
    },
    {
      "id": "missing-delay-validation",
      "name": "Not validating delay values before publishing",
      "problem": "Passing unvalidated metadata.delay directly to message broker without type/range checks",
      "why_bad": [
        "Runtime errors from invalid types (string, object, null)",
        "Unexpected behavior from negative delays",
        "NaN or undefined causes broker errors",
        "No fallback strategy for invalid input"
      ],
      "better_approach": "Validate delay is number >= 0, fall back to immediate delivery for invalid values",
      "tags": ["validation", "type-safety", "error-handling", "delayed-messages"]
    },
    {
      "id": "insufficient-edge-case-testing",
      "name": "Testing only happy path for optional numeric fields",
      "problem": "Only testing valid delay values without covering invalid input scenarios",
      "why_bad": [
        "Production failures from unexpected user input",
        "No visibility into how code handles edge cases",
        "Regressions go undetected during refactoring",
        "Unclear fallback behavior"
      ],
      "better_approach": "Test 8+ edge cases: negative, zero, string, null, undefined, NaN, object, Infinity",
      "tags": ["testing", "edge-cases", "validation", "robustness"]
    }
  ],
  "metadata": {
    "total_skills": 12,
    "total_patterns": 3,
    "total_anti_patterns": 7,
    "last_updated": "2026-01-11T15:22:00Z",
    "created_at": "2026-01-05T00:00:00Z",
    "last_task": "AIRIS-47: feat(rabbitmq): add x-delayed-message support with dual exchange architecture"
  }
}
