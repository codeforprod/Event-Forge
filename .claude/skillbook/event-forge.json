{
  "version": "1.0.2",
  "service": "event-forge",
  "description": "Skillbook for Event-Forge project - patterns, learnings, and best practices",
  "skills": [
    {
      "id": "changesets-monorepo-setup",
      "category": "best-practices",
      "title": "Setting up Changesets for monorepo package publishing",
      "problem": "Need automated version management and publishing for multiple NPM packages in a monorepo",
      "solution": "Use Changesets with linked configuration to synchronize versions across all packages",
      "implementation": {
        "steps": [
          "Install @changesets/cli as dev dependency",
          "Run 'pnpm changeset init' to create .changeset directory",
          "Configure .changeset/config.json with 'linked' array containing package patterns",
          "Set 'access' to 'public' for NPM publishing",
          "Add scripts: changeset, version-packages, ci:publish, release"
        ],
        "config_example": {
          "linked": [["@event-forge/inbox-outbox-*"]],
          "access": "public",
          "baseBranch": "main"
        }
      },
      "benefits": [
        "Decouples versioning from git commits",
        "Auto-generates CHANGELOG",
        "Creates version bump PRs automatically",
        "Handles monorepo inter-package dependencies"
      ],
      "tags": ["changesets", "monorepo", "publishing", "npm", "versioning"]
    },
    {
      "id": "pypi-trusted-publishers",
      "category": "best-practices",
      "title": "Using PyPI Trusted Publishers for secure publishing",
      "problem": "Need secure PyPI publishing without manual API tokens",
      "solution": "Use PyPI Trusted Publishers with GitHub Actions OIDC",
      "implementation": {
        "steps": [
          "Configure PyPI project with Trusted Publisher settings (owner, repo, workflow, environment)",
          "Use pypa/gh-action-pypi-publish@release/v1 action",
          "Set permissions: id-token: write, contents: read",
          "Use GitHub environment 'pypi' for protection",
          "Enable attestations: true for PEP 740 compliance"
        ],
        "github_workflow": {
          "environment": {
            "name": "pypi",
            "url": "https://pypi.org/p/{package-name}"
          },
          "permissions": {
            "id-token": "write",
            "contents": "read"
          }
        }
      },
      "benefits": [
        "No manual API tokens to manage",
        "Automatic package attestations (PEP 740)",
        "More secure than token-based auth",
        "Integrated with GitHub Actions"
      ],
      "tags": ["pypi", "publishing", "security", "oidc", "trusted-publishers"]
    },
    {
      "id": "npm-python-version-sync",
      "category": "automation",
      "title": "Synchronizing NPM and Python package versions",
      "problem": "Monorepo with both NPM and Python packages needs synchronized versions",
      "solution": "Create sync script that updates Python pyproject.toml from NPM package.json",
      "implementation": {
        "script": "scripts/sync-python-version.js",
        "approach": "Read version from packages/core/package.json, update pyproject.toml using regex replacement",
        "integration": "Run as GitHub Actions step before publishing Python package",
        "script_example": "fs.readFileSync + regex replace /^version\\s*=\\s*\"[^\"]*\"/m"
      },
      "benefits": [
        "Single source of truth for versions (NPM core package)",
        "Automated - no manual version updates needed",
        "Runs in CI pipeline before publishing"
      ],
      "tags": ["version-sync", "npm", "python", "automation", "monorepo"]
    },
    {
      "id": "changesets-github-actions-workflow",
      "category": "ci-cd",
      "title": "Implementing Changesets with GitHub Actions",
      "problem": "Need automated workflow to create version PRs and publish packages",
      "solution": "Use changesets/action@v1 in GitHub Actions workflow",
      "implementation": {
        "workflow_structure": {
          "trigger": "push to main branch",
          "concurrency": "prevent parallel executions",
          "job_outputs": "published, publishedPackages for conditional downstream jobs",
          "steps": [
            "Checkout with fetch-depth: 0",
            "Setup pnpm and Node.js",
            "Build and test",
            "Run changesets action with publish command"
          ]
        },
        "changesets_action_config": {
          "commit": "chore(release): version packages",
          "title": "chore(release): version packages",
          "publish": "pnpm ci:publish"
        }
      },
      "workflow": [
        "Developer creates changeset locally",
        "Changes merged to main",
        "Workflow creates 'Version Packages' PR (if changesets exist)",
        "Merging version PR triggers publish job",
        "Published packages trigger downstream jobs (e.g., Python publishing)"
      ],
      "tags": ["changesets", "github-actions", "ci-cd", "automation", "publishing"]
    },
    {
      "id": "conditional-pypi-publishing",
      "category": "ci-cd",
      "title": "Conditional PyPI publishing based on NPM release",
      "problem": "Python package should only publish when NPM packages are published",
      "solution": "Use job outputs and conditional execution in GitHub Actions",
      "implementation": {
        "pattern": "needs: release, if: needs.release.outputs.published == 'true'",
        "job_outputs": "Set outputs in NPM job from changesets action",
        "conditional_job": "PyPI job depends on NPM job and checks published output"
      },
      "benefits": [
        "Prevents unnecessary PyPI publishes",
        "Ensures version synchronization",
        "Cleaner workflow execution"
      ],
      "tags": ["github-actions", "conditional-execution", "pypi", "npm", "workflow"]
    },
    {
      "id": "typeorm-pessimistic-lock-transaction",
      "category": "bug-patterns",
      "title": "TypeORM pessimistic locks must be wrapped in transactions",
      "problem": "PessimisticLockTransactionRequiredError when using setLock('pessimistic_write')",
      "symptoms": [
        "Error: 'An optimistic lock can only be used inside a transaction'",
        "Method using pessimistic_write lock fails at runtime",
        "Query builder with FOR UPDATE SKIP LOCKED throws error"
      ],
      "root_cause": "TypeORM requires pessimistic locks (FOR UPDATE) to be executed within an active transaction context",
      "investigation": [
        "Check if query builder uses setLock('pessimistic_write') or setLock('pessimistic_read')",
        "Verify if the operation is wrapped in dataSource.transaction()",
        "Examine if operations use this.repository vs manager.getRepository()"
      ],
      "solution": {
        "pattern": "Wrap entire method in dataSource.transaction() and use manager.getRepository()",
        "before": "async fetchAndLock() { const query = this.repository.createQueryBuilder().setLock('pessimistic_write'); }",
        "after": "async fetchAndLock() { return this.dataSource.transaction(async (manager) => { const query = manager.getRepository(Entity).createQueryBuilder().setLock('pessimistic_write'); }); }",
        "key_changes": [
          "Wrap in this.dataSource.transaction(async (manager) => {...})",
          "Replace this.repository with manager.getRepository(EntityClass)",
          "All operations in method must use manager.getRepository()",
          "Return value from transaction callback"
        ]
      },
      "prevention": [
        "Always use pessimistic locks within transaction boundaries",
        "Code review checklist: setLock() calls must be inside transaction()",
        "Add integration tests for concurrent lock scenarios",
        "Document transaction requirements in method comments"
      ],
      "related_patterns": [
        "SKIP LOCKED for non-blocking concurrent processing",
        "Atomic status updates within same transaction as lock",
        "Manager pattern for transactional repositories"
      ],
      "example": {
        "file": "packages/adapter-typeorm/src/repositories/typeorm-outbox.repository.ts",
        "method": "fetchAndLockPending",
        "fix_commit": "AIRIS-46"
      },
      "tags": ["typeorm", "pessimistic-lock", "transaction", "postgresql", "concurrency", "bug-fix"]
    },
    {
      "id": "nestjs-lifecycle-hooks",
      "category": "best-practices",
      "title": "Automatic service lifecycle management in NestJS modules",
      "problem": "Consumers must manually start/stop polling in their own lifecycle hooks, leading to boilerplate code",
      "solution": "Create a lifecycle service implementing OnApplicationBootstrap and OnApplicationShutdown that automatically manages service lifecycle",
      "implementation": {
        "steps": [
          "Create service implementing OnApplicationBootstrap and OnApplicationShutdown",
          "Inject the service to manage (e.g., OutboxService)",
          "Call service methods in lifecycle hooks",
          "Add lifecycle.autoStart configuration option (default: true)",
          "Conditionally provide lifecycle service based on configuration",
          "Export lifecycle service for manual control if needed"
        ],
        "code_example": {
          "service": "@Injectable() class EventForgeLifecycleService { constructor(@Inject(TOKEN) private service) {} onApplicationBootstrap() { this.service.start(); } onApplicationShutdown() { this.service.stop(); } }",
          "conditional_provider": "if (options.lifecycle?.autoStart !== false) { providers.push(LifecycleService); }",
          "config": "{ lifecycle: { autoStart: true } }"
        }
      },
      "benefits": [
        "Eliminates boilerplate lifecycle code in consumer applications",
        "Ensures consistent lifecycle management",
        "Graceful shutdown handling",
        "Optional - can be disabled for custom control"
      ],
      "tags": ["nestjs", "lifecycle", "automation", "di", "best-practice"]
    },
    {
      "id": "nestjs-conditional-providers",
      "category": "best-practices",
      "title": "Conditional provider registration based on configuration",
      "problem": "Need to conditionally provide services based on user configuration options",
      "solution": "Use factory providers that check configuration and return null when service should not be provided",
      "implementation": {
        "pattern": "useFactory with conditional logic",
        "code_example": "{ provide: Service, useFactory: (config) => config.enabled !== false ? new Service() : null, inject: [CONFIG] }",
        "null_safe_default": "Use !== false instead of === true to default to true (treats undefined/null as true)"
      },
      "benefits": [
        "Clean DI without complex conditional module registration",
        "Type-safe configuration",
        "Easy to test with different configurations"
      ],
      "tags": ["nestjs", "di", "conditional-logic", "configuration"]
    },
    {
      "id": "eslint-import-order",
      "category": "code-quality",
      "title": "ESLint import/order rule compliance",
      "problem": "ESLint import/order errors: 'There should be at least one empty line between import groups'",
      "solution": "Add empty line between external package imports and internal (relative) imports",
      "implementation": {
        "correct_pattern": "import { External } from '@package';\nimport { External2 } from '@package2';\n\nimport { Internal } from './internal';",
        "groups": "1. External packages (@namespace, npm packages), 2. Empty line, 3. Internal imports (./relative)"
      },
      "tags": ["eslint", "import-order", "code-style", "linting"]
    },
    {
      "id": "rabbitmq-x-delay-header-mapping",
      "category": "best-practices",
      "title": "Mapping metadata.delay to x-delay header for RabbitMQ delayed messages",
      "problem": "Need to map application-level delay metadata to RabbitMQ-specific x-delay header",
      "solution": "Extract and validate metadata.delay field, then map to x-delay header only for valid delays",
      "implementation": {
        "validation_rules": [
          "Must be a number type",
          "Must be >= 0 (non-negative)",
          "Reject: string, null, undefined, NaN, object, negative numbers",
          "Accept: positive numbers, zero (treated as immediate), Infinity"
        ],
        "extraction_pattern": "Check existence → type check → range check → return number or null",
        "header_mapping": "Only add x-delay header if delay is valid number >= 0"
      },
      "benefits": [
        "Type-safe delay handling",
        "Graceful degradation to immediate delivery on invalid input",
        "Clear separation between metadata (application) and headers (broker)",
        "Prevents runtime errors from invalid delay values"
      ],
      "code_example": "private extractDelay(message: OutboxMessage): number | null {\n  if (!message.metadata?.delay) return null;\n  const delay = message.metadata.delay;\n  if (typeof delay !== 'number') return null;\n  if (delay < 0) return null;\n  return delay;\n}",
      "tags": ["rabbitmq", "validation", "type-safety", "header-mapping", "delayed-messages"]
    },
    {
      "id": "comprehensive-edge-case-testing",
      "category": "testing",
      "title": "Testing edge cases for optional numeric fields with fallback behavior",
      "problem": "Need to ensure robust handling of invalid input for optional numeric configuration fields",
      "solution": "Create comprehensive test suite covering all invalid value types and edge cases",
      "implementation": {
        "test_categories": [
          "Type mismatches (string, object, null, undefined)",
          "Special numeric values (NaN, Infinity, -Infinity)",
          "Range violations (negative numbers, zero)",
          "Valid values (positive numbers, large numbers)"
        ],
        "test_pattern": "Arrange → Act → Assert fallback behavior",
        "coverage_targets": [
          "Test 8+ invalid value scenarios",
          "Verify graceful fallback for each",
          "Ensure no exceptions thrown",
          "Validate correct behavior for valid values"
        ]
      },
      "benefits": [
        "Prevents production failures from unexpected input",
        "Documents expected behavior through tests",
        "Catches regressions during refactoring",
        "Builds confidence in error handling"
      ],
      "edge_cases_tested": [
        "negative delay → immediate delivery",
        "string delay → immediate delivery",
        "null delay → immediate delivery",
        "undefined delay → immediate delivery",
        "NaN delay → immediate delivery",
        "object delay → immediate delivery",
        "zero delay → immediate delivery",
        "Infinity delay → delayed delivery (valid)"
      ],
      "tags": ["testing", "edge-cases", "validation", "robustness", "type-safety"]
    },
    {
      "id": "plugin-prerequisite-documentation",
      "category": "documentation",
      "title": "Documenting external plugin dependencies in library READMEs",
      "problem": "Library features depend on external RabbitMQ plugins that must be installed separately",
      "solution": "Create dedicated Prerequisites section with installation commands and configuration examples",
      "implementation": {
        "structure": [
          "Prerequisites heading before Usage section",
          "Clear statement of requirement (what plugin, why needed)",
          "Installation commands (bash examples)",
          "Configuration examples (exchange setup)",
          "Link to official plugin documentation"
        ],
        "content_elements": [
          "Command-line installation (rabbitmq-plugins enable)",
          "Server restart instructions",
          "Exchange configuration (rabbitmqadmin or programmatic)",
          "Error handling guidance (what happens if plugin missing)"
        ]
      },
      "benefits": [
        "Prevents user confusion and support requests",
        "Clear setup path for new users",
        "Reduces integration time",
        "Sets correct expectations about external dependencies"
      ],
      "example_structure": "## Prerequisites\n\nRequires rabbitmq_delayed_message_exchange plugin.\n\n**Installation:**\n```bash\nrabbitmq-plugins enable rabbitmq_delayed_message_exchange\nrabbitmqctl restart\n```\n\n**Exchange Configuration:**\n```bash\nrabbitmqadmin declare exchange name=events.delayed type=x-delayed-message\n```",
      "tags": ["documentation", "prerequisites", "dependencies", "user-guidance", "rabbitmq"]
    },
    {
      "id": "empty-string-property-detection",
      "category": "best-practices",
      "title": "Detecting presence of empty string properties in JavaScript/TypeScript",
      "problem": "Need to distinguish between missing property and empty string property for optional string metadata fields",
      "solution": "Use 'in' operator instead of falsy check to detect property presence",
      "implementation": {
        "wrong_approach": "if (!object?.property) return null; // Treats empty string as absent",
        "correct_approach": "if (!object || !('property' in object)) return null; // Detects presence regardless of value",
        "validation_pattern": "Check property existence with 'in', then validate type and value separately"
      },
      "use_cases": [
        "Optional routing keys where empty string is valid (fanout exchanges)",
        "Custom exchange names that could be empty",
        "Any metadata field where empty string has semantic meaning"
      ],
      "benefits": [
        "Correctly handles empty strings as valid values",
        "Clear separation between absent and empty",
        "Type-safe property detection",
        "Works with optional chaining"
      ],
      "code_example": "// WRONG - treats empty string as absent\nif (!message.metadata?.routingKey) return null;\n\n// CORRECT - detects property presence\nif (!message.metadata || !('routingKey' in message.metadata)) return null;\nif (typeof message.metadata.routingKey !== 'string') return null;\nreturn message.metadata.routingKey; // Can be empty string",
      "tags": ["javascript", "typescript", "validation", "empty-string", "property-detection"]
    },
    {
      "id": "exponential-backoff-with-jitter",
      "category": "best-practices",
      "title": "Implement exponential backoff with jitter for retry mechanisms",
      "problem": "Multiple messages retrying simultaneously causes retry storms (thundering herd problem)",
      "solution": "Use exponential backoff with random jitter to spread retry attempts over time",
      "implementation": {
        "steps": [
          "Calculate base exponential delay: base * 2^retryCount",
          "Cap at maximum delay to prevent excessive wait times",
          "Add random jitter (±10%) to prevent synchronized retries",
          "Return final delay in milliseconds"
        ],
        "code_example": "private calculateBackoff(retryCount: number): number {\n  const baseDelaySeconds = this.config.backoffBaseSeconds;\n  const maxDelaySeconds = this.config.maxBackoffSeconds;\n  \n  const exponentialDelay = baseDelaySeconds * Math.pow(2, retryCount);\n  const cappedDelay = Math.min(exponentialDelay, maxDelaySeconds);\n  \n  const jitter = cappedDelay * 0.1 * (Math.random() * 2 - 1);\n  const finalDelay = cappedDelay + jitter;\n  \n  return Math.max(0, finalDelay * 1000);\n}",
        "formula": "min(base * 2^retryCount, maxBackoff) + jitter",
        "jitter_calculation": "±10% randomization: delay * 0.1 * (Math.random() * 2 - 1)",
        "files": ["packages/core/src/services/outbox.service.ts:173-189"]
      },
      "when_to_use": [
        "Any retry mechanism with multiple concurrent workers",
        "Message processing systems with backoff",
        "API rate limiting retry logic",
        "Database connection retry logic"
      ],
      "when_to_avoid": [
        "Single-threaded retry (no thundering herd risk)",
        "Time-critical operations requiring immediate retry",
        "Fixed-interval polling requirements"
      ],
      "benefits": [
        "Prevents thundering herd problem",
        "Reduces system load during failures",
        "Improves overall system stability",
        "Spreads retry attempts over time"
      ],
      "related": ["scheduled-retry-pattern", "atomic-retry-increment"],
      "tags": ["retry", "exponential-backoff", "jitter", "concurrency", "best-practices"]
    },
    {
      "id": "scheduled-retry-pattern",
      "category": "architecture",
      "title": "Schedule future retries with scheduledAt field",
      "problem": "Immediate retries after failure cause cascading failures and waste resources",
      "solution": "Add scheduledAt timestamp field to schedule future retry attempts",
      "implementation": {
        "steps": [
          "Add scheduledAt (nullable Date) field to message entity",
          "Calculate backoff delay when marking message as failed",
          "Set scheduledAt = now + backoff delay",
          "Query only messages where scheduledAt IS NULL OR scheduledAt <= now",
          "Add compound index on (status, scheduledAt) for efficient queries"
        ],
        "code_example": "// Mark failed with scheduled retry\nawait this.repository.update(id, {\n  status: 'failed',\n  retryCount: () => 'retry_count + 1',\n  scheduledAt: new Date(Date.now() + backoffMs),\n  lastError: error\n});\n\n// Query retryable messages\nconst retryable = await this.repository.find({\n  where: {\n    status: 'failed',\n    retryCount: LessThan(maxRetries),\n    scheduledAt: Or(IsNull(), LessThanOrEqual(now))\n  }\n});",
        "database_fields": {
          "scheduledAt": "TIMESTAMP NULL - When message should be retried",
          "index": "CREATE INDEX idx_retry ON messages (status, scheduledAt, retryCount)"
        },
        "files": [
          "packages/adapter-typeorm/src/repositories/typeorm-outbox.repository.ts",
          "packages/adapter-mongoose/src/repositories/mongoose-outbox.repository.ts"
        ]
      },
      "when_to_use": [
        "Any system with automatic retries",
        "Message processing pipelines",
        "Job queues with retry logic",
        "Failed operation recovery"
      ],
      "when_to_avoid": [
        "Retry must happen immediately",
        "No database backing (in-memory only)",
        "Simple single-attempt operations"
      ],
      "benefits": [
        "Prevents immediate retry storms",
        "Reduces database query load",
        "Allows exponential backoff implementation",
        "Clear audit trail of scheduled retries"
      ],
      "related": ["exponential-backoff-with-jitter", "atomic-retry-increment"],
      "tags": ["retry", "scheduling", "database", "architecture", "scalability"]
    },
    {
      "id": "atomic-retry-increment",
      "category": "bug-patterns",
      "title": "Use atomic database operations for retry count increments",
      "problem": "Race conditions when multiple instances read-modify-write retry counters simultaneously",
      "solution": "Use database atomic increment operations instead of read-modify-write pattern",
      "implementation": {
        "steps": [
          "Never read retry count, modify it, then write back",
          "Use SQL INCREMENT or MongoDB $inc operators",
          "Apply atomic operation in same query that updates status"
        ],
        "code_example_typeorm": "// WRONG - read-modify-write (race condition)\nconst message = await this.repository.findOne(id);\nmessage.retryCount += 1;\nawait this.repository.save(message);\n\n// CORRECT - atomic increment\nawait this.repository\n  .createQueryBuilder()\n  .update()\n  .set({\n    status: InboxMessageStatus.FAILED,\n    retryCount: () => 'retry_count + 1',  // SQL-level atomic increment\n    scheduledAt: scheduledAt,\n    lastError: error\n  })\n  .where('id = :id', { id })\n  .execute();",
        "code_example_mongoose": "// CORRECT - atomic increment with $inc\nawait this.model.findByIdAndUpdate(id, {\n  $set: {\n    status: InboxMessageStatus.FAILED,\n    scheduledAt: scheduledAt,\n    lastError: error\n  },\n  $inc: { retryCount: 1 }  // MongoDB atomic increment\n});",
        "files": [
          "packages/adapter-typeorm/src/repositories/typeorm-inbox.repository.ts",
          "packages/adapter-mongoose/src/repositories/mongoose-inbox.repository.ts"
        ]
      },
      "when_to_use": [
        "Any counter updated by multiple concurrent processes",
        "Retry counters in distributed systems",
        "Statistics/metrics collection",
        "Version numbers or sequence counters"
      ],
      "when_to_avoid": [
        "Single-threaded applications",
        "Counters that don't need strict accuracy",
        "Read-only operations"
      ],
      "benefits": [
        "Prevents race conditions",
        "Guarantees accurate retry counts",
        "Safe for horizontal scaling",
        "No need for distributed locks"
      ],
      "related": ["scheduled-retry-pattern", "typeorm-pessimistic-lock-transaction"],
      "tags": ["concurrency", "race-condition", "atomic-operations", "database", "bug-prevention"]
    },
    {
      "id": "backward-compatible-feature-flags",
      "category": "best-practices",
      "title": "Use opt-in feature flags for backward-compatible library updates",
      "problem": "Adding new features to existing library without breaking existing consumers",
      "solution": "Add optional configuration flags that default to false (disabled) for new features",
      "implementation": {
        "steps": [
          "Add optional boolean config field with ? modifier",
          "Default to false in service constructor",
          "Check flag before enabling new behavior",
          "Document migration path in CHANGELOG"
        ],
        "code_example": "export interface InboxConfig {\n  // Existing config...\n  enableRetry?: boolean;  // NEW: default false (backward compatible!)\n  maxRetries?: number;\n  retryPollingInterval?: number;\n}\n\nclass InboxService {\n  constructor(config: InboxConfig) {\n    this.enableRetry = config.enableRetry ?? false;  // Explicit default\n    if (this.enableRetry) {\n      this.startRetryPolling();\n    }\n  }\n}",
        "migration_documentation": "## Migration Guide\n\n### Enabling Retry (Optional)\n\nRetry is disabled by default. To enable:\n\n```typescript\nInboxOutboxModule.forRoot({\n  inbox: {\n    enableRetry: true,  // NEW: opt-in\n    maxRetries: 3\n  }\n});\n```",
        "files": [
          "packages/core/src/services/inbox.service.ts",
          "packages/core/src/interfaces/config.interface.ts"
        ]
      },
      "when_to_use": [
        "Adding new functionality to public library",
        "Behavior change that might affect existing users",
        "Performance-impacting features",
        "Features requiring additional configuration"
      ],
      "when_to_avoid": [
        "Bug fixes (should apply immediately)",
        "Security fixes (should not be optional)",
        "Internal refactoring with no behavior change",
        "New library (no backward compatibility needed)"
      ],
      "benefits": [
        "No breaking changes for existing users",
        "Gradual migration path",
        "Users can test before enabling",
        "Clear opt-in intent"
      ],
      "related": ["nestjs-conditional-providers"],
      "tags": ["backward-compatibility", "feature-flags", "library-design", "migration", "best-practices"]
    },
    {
      "id": "retry-query-optimization",
      "category": "best-practices",
      "title": "Optimize database queries for retry message selection",
      "problem": "Slow queries when selecting retryable messages from large tables",
      "solution": "Create compound indexes on all fields used in retry selection queries",
      "implementation": {
        "steps": [
          "Identify all WHERE clause fields in retry query",
          "Create compound index in query execution order",
          "For PostgreSQL: Use partial index on status = 'failed'",
          "For MongoDB: Create compound index on all query fields"
        ],
        "code_example_typeorm": "// Query: status='failed' AND retryCount < maxRetries AND scheduledAt <= now\n@Index('idx_inbox_retry', ['status', 'scheduledAt'], {\n  where: \"status = 'failed'\",  // PostgreSQL partial index\n})\n@Entity()\nexport class InboxMessageEntity {\n  @Column() status: string;\n  @Column() retryCount: number;\n  @Column({ nullable: true }) scheduledAt: Date;\n}",
        "code_example_mongoose": "// MongoDB compound index\nInboxMessageSchema.index(\n  { status: 1, retryCount: 1, scheduledAt: 1, createdAt: 1 },\n  { name: 'idx_inbox_retry' }\n);",
        "query_pattern": "SELECT * FROM inbox\nWHERE status = 'failed'\n  AND retryCount < maxRetries\n  AND (scheduledAt IS NULL OR scheduledAt <= NOW())\nORDER BY createdAt ASC\nLIMIT 100;",
        "files": [
          "packages/adapter-typeorm/src/entities/inbox-message.entity.ts",
          "packages/adapter-mongoose/src/schemas/inbox-message.schema.ts"
        ]
      },
      "when_to_use": [
        "Tables with >10k rows",
        "Frequent retry queries (polling)",
        "Multiple query conditions",
        "Performance-critical systems"
      ],
      "when_to_avoid": [
        "Small tables (<1k rows)",
        "Infrequent queries",
        "Single-condition queries"
      ],
      "benefits": [
        "Fast query execution on large tables",
        "Reduced database CPU usage",
        "Scalable to millions of messages",
        "Consistent query performance"
      ],
      "index_strategy": {
        "postgresql": "Partial index on status + scheduledAt (filters most rows)",
        "mongodb": "Compound index on all query fields in order"
      },
      "related": ["scheduled-retry-pattern"],
      "tags": ["database", "optimization", "indexing", "performance", "query-tuning"]
    }
  ],
  "patterns": [
    {
      "id": "flexible-message-routing",
      "category": "architecture",
      "name": "Flexible message routing via metadata overrides",
      "context": "Message publisher that needs to support both default routing and custom routing per message",
      "pattern": "Extract optional metadata fields to override default routing behavior while maintaining backward compatibility",
      "components": [
        "Default routing builder - Constructs routing key from message properties",
        "Metadata extractors - Validate and extract custom routing/exchange from metadata",
        "Override logic - Apply custom values when present, fallback to defaults",
        "Type validation - Ensure metadata fields are correct types before use"
      ],
      "implementation_details": {
        "routing_key_override": "metadata.routingKey (string) overrides default {aggregateType}.{eventType}",
        "exchange_override": "metadata.exchange (string) overrides default exchange (immediate messages only)",
        "validation": "Use 'in' operator for property detection, typeof for type checks",
        "fallback": "Invalid values gracefully fall back to default behavior"
      },
      "trade_offs": {
        "pros": [
          "Flexible routing without breaking backward compatibility",
          "Per-message control over routing",
          "Supports advanced patterns (fanout, priority queues)",
          "Type-safe with graceful fallback"
        ],
        "cons": [
          "More complex routing logic",
          "Need comprehensive edge case testing",
          "Documentation must explain override behavior clearly"
        ]
      },
      "when_to_use": [
        "Need per-message routing control",
        "Supporting multiple routing patterns in same publisher",
        "Gradual migration from default to custom routing",
        "Multi-tenant systems with routing isolation"
      ],
      "when_to_avoid": [
        "Single fixed routing pattern",
        "No need for runtime routing decisions",
        "Simple point-to-point messaging"
      ],
      "related_patterns": ["dual-exchange-delayed-messages", "metadata-driven-configuration"]
    },
    {
      "id": "monorepo-publishing-architecture",
      "category": "architecture",
      "name": "Monorepo multi-platform publishing architecture",
      "context": "Publishing packages to multiple registries (NPM + PyPI) from single monorepo",
      "pattern": "Use Changesets for NPM version management, sync script for Python versions, GitHub Actions for automation",
      "components": [
        "Changesets - NPM version management and changelog",
        "Version sync script - Synchronize NPM to Python",
        "GitHub Actions workflows - Automation (release.yml for publishing, ci.yml for validation)",
        "Trusted Publishers - Secure PyPI publishing without tokens"
      ],
      "trade_offs": {
        "pros": [
          "Single source of truth for versions",
          "Automated version bumps and publishing",
          "Secure (no manual tokens for PyPI)",
          "Clear developer workflow"
        ],
        "cons": [
          "Requires external setup (NPM token, PyPI trusted publisher config)",
          "Learning curve for Changesets workflow",
          "Two-step process (version PR, then publish)"
        ]
      },
      "when_to_use": "Multi-platform monorepos with frequent releases",
      "when_to_avoid": "Single package projects or infrequent manual releases"
    },
    {
      "id": "nestjs-lifecycle-automation",
      "category": "architecture",
      "name": "Automatic lifecycle management in NestJS libraries",
      "context": "Building NestJS libraries that manage background services requiring start/stop",
      "pattern": "Provide optional lifecycle service that automatically manages service lifecycle via NestJS hooks",
      "components": [
        "Lifecycle service implementing OnApplicationBootstrap and OnApplicationShutdown",
        "Configuration option (lifecycle.autoStart) to enable/disable automatic management",
        "Conditional provider registration based on configuration",
        "Service export for manual control when autoStart is disabled"
      ],
      "trade_offs": {
        "pros": [
          "Zero boilerplate for consumers (works out of the box)",
          "Consistent lifecycle management",
          "Graceful shutdown handling",
          "Optional - can be disabled for custom control"
        ],
        "cons": [
          "Adds complexity to module registration logic",
          "Less explicit control (hidden lifecycle management)",
          "Requires understanding of conditional providers"
        ]
      },
      "when_to_use": "Libraries managing background services (polling, scheduled tasks, connections)",
      "when_to_avoid": "Simple libraries without lifecycle needs or stateless utilities"
    },
    {
      "id": "dual-exchange-delayed-messages",
      "category": "architecture",
      "name": "Dual exchange pattern for delayed message delivery",
      "context": "Message publisher needs to support both immediate and delayed delivery without performance penalty",
      "pattern": "Use two separate exchanges (direct + delayed) with automatic selection based on message metadata",
      "components": [
        "Direct exchange - Handles immediate messages (standard topic exchange)",
        "Delayed exchange - Handles delayed messages (x-delayed-message type)",
        "Selection logic - Routes to appropriate exchange based on metadata.delay presence",
        "Header mapping - Converts metadata.delay to x-delay header for delayed exchange"
      ],
      "implementation_details": {
        "routing_logic": "if (delay !== null) use delayedExchange else use directExchange",
        "header_transformation": "metadata.delay (milliseconds) → x-delay header (milliseconds)",
        "routing_key_format": "{aggregateType}.{eventType}"
      },
      "trade_offs": {
        "pros": [
          "No delay overhead for immediate messages",
          "Clear separation of concerns (immediate vs delayed)",
          "Can monitor each exchange independently",
          "Delayed exchange failure doesn't affect immediate delivery"
        ],
        "cons": [
          "Requires two exchange configurations",
          "Requires rabbitmq_delayed_message_exchange plugin",
          "More complex RabbitMQ topology"
        ]
      },
      "when_to_use": [
        "Mix of immediate and delayed messages in same system",
        "High-volume immediate messages with occasional delayed ones",
        "Need separate monitoring/metrics for immediate vs delayed"
      ],
      "when_to_avoid": [
        "Only delayed messages (single delayed exchange sufficient)",
        "Cannot install RabbitMQ plugins",
        "Simple pub-sub without delay requirements"
      ],
      "related_patterns": ["single-exchange-with-ttl", "queue-level-delays"]
    },
    {
      "id": "inbox-retry-architecture",
      "category": "architecture",
      "name": "Inbox message retry with exponential backoff",
      "context": "INBOX messages that fail processing should be automatically retried with backoff",
      "pattern": "Opt-in retry mechanism with atomic retry counter, scheduled retries, and exponential backoff",
      "components": [
        "Configuration - enableRetry flag (default: false) for backward compatibility",
        "Database fields - retryCount, maxRetries, scheduledAt for tracking",
        "Backoff calculator - Exponential delay with jitter",
        "Retry polling - Background job finding retryable messages",
        "Atomic operations - Database-level retry counter increment"
      ],
      "implementation_details": {
        "retry_trigger": "findRetryable() query + polling mechanism",
        "backoff_formula": "min(base * 2^retryCount, maxBackoff) + jitter(±10%)",
        "atomic_increment": "SQL: retry_count + 1 | MongoDB: $inc",
        "query_optimization": "Compound index on (status, retryCount, scheduledAt)"
      },
      "trade_offs": {
        "pros": [
          "Backward compatible (opt-in via enableRetry flag)",
          "Prevents retry storms with backoff + jitter",
          "Safe for horizontal scaling (atomic operations)",
          "Similar to OUTBOX retry (consistent pattern)"
        ],
        "cons": [
          "Additional database fields required",
          "Polling overhead (mitigated by scheduling)",
          "More complex than fail-once pattern"
        ]
      },
      "when_to_use": [
        "Transient failures are expected (network, downstream service)",
        "Message processing must eventually succeed",
        "Idempotent message handlers",
        "Distributed systems with eventual consistency"
      ],
      "when_to_avoid": [
        "Non-idempotent operations without deduplication",
        "Messages that should never be reprocessed",
        "Simple systems where failure is rare"
      ],
      "related_patterns": ["exponential-backoff-with-jitter", "scheduled-retry-pattern", "atomic-retry-increment"]
    }
  ],
  "anti_patterns": [
    {
      "id": "falsy-check-for-empty-strings",
      "name": "Using falsy checks to detect optional string properties",
      "problem": "Using !object?.property to check if optional string property is present",
      "why_bad": [
        "Empty strings are falsy - treated as absent when they may be intentional",
        "Cannot distinguish between undefined/null and empty string",
        "Breaks use cases where empty string has semantic meaning (fanout routing)",
        "Silent bugs - no error, just wrong behavior"
      ],
      "better_approach": "Use 'in' operator to check property existence: !('property' in object)",
      "example": {
        "wrong": "if (!metadata?.routingKey) return null; // Treats '' as absent",
        "correct": "if (!metadata || !('routingKey' in metadata)) return null; // Detects '' as present"
      },
      "tags": ["javascript", "typescript", "validation", "empty-string", "anti-pattern"]
    },
    {
      "id": "manual-version-updates",
      "name": "Manual version updates in monorepos",
      "problem": "Manually updating version numbers in multiple package.json files",
      "why_bad": [
        "Error-prone (easy to miss packages)",
        "Time-consuming",
        "No automatic changelog",
        "Inter-package dependency versions can get out of sync"
      ],
      "better_approach": "Use Changesets with linked configuration for automatic version management",
      "tags": ["versioning", "monorepo", "manual-work"]
    },
    {
      "id": "pypi-api-tokens-in-ci",
      "name": "Using PyPI API tokens in GitHub Actions",
      "problem": "Storing PyPI API tokens as GitHub secrets",
      "why_bad": [
        "Security risk (tokens can leak)",
        "Manual token rotation required",
        "No automatic package attestations",
        "Less secure than OIDC"
      ],
      "better_approach": "Use PyPI Trusted Publishers with GitHub Actions OIDC",
      "tags": ["security", "pypi", "tokens", "oidc"]
    },
    {
      "id": "pessimistic-lock-without-transaction",
      "name": "Using pessimistic locks outside transactions in TypeORM",
      "problem": "Calling setLock('pessimistic_write') on query builder without wrapping in transaction",
      "why_bad": [
        "Throws PessimisticLockTransactionRequiredError at runtime",
        "Violates TypeORM's transaction requirements",
        "Can lead to race conditions if not properly handled",
        "Tests may pass but production fails"
      ],
      "better_approach": "Always wrap pessimistic lock operations in dataSource.transaction()",
      "example": {
        "wrong": "this.repository.createQueryBuilder().setLock('pessimistic_write').getMany()",
        "correct": "this.dataSource.transaction(async (manager) => manager.getRepository(Entity).createQueryBuilder().setLock('pessimistic_write').getMany())"
      },
      "tags": ["typeorm", "pessimistic-lock", "transaction", "anti-pattern"]
    },
    {
      "id": "manual-lifecycle-in-consumers",
      "name": "Requiring consumers to manually manage service lifecycle",
      "problem": "NestJS library requires every consumer to add onApplicationBootstrap/onApplicationShutdown hooks",
      "why_bad": [
        "Boilerplate code in every consumer",
        "Easy to forget, leading to resource leaks",
        "Inconsistent implementation across consumers",
        "Poor developer experience"
      ],
      "better_approach": "Provide automatic lifecycle management with opt-out configuration",
      "example": {
        "bad": "Consumer must: constructor(service) {} onApplicationBootstrap() { service.start(); }",
        "good": "Library handles automatically via lifecycle service"
      },
      "tags": ["nestjs", "lifecycle", "dx", "boilerplate"]
    },
    {
      "id": "single-exchange-for-all-messages",
      "name": "Using single exchange for both immediate and delayed messages",
      "problem": "Routing all messages (immediate and delayed) through x-delayed-message exchange",
      "why_bad": [
        "Performance overhead: All messages go through delay plugin even if delay=0",
        "Cannot monitor immediate vs delayed separately",
        "Plugin failure affects all message delivery",
        "Wastes resources checking delay for immediate messages"
      ],
      "better_approach": "Use dual exchange pattern: direct exchange for immediate, delayed exchange for delayed messages",
      "tags": ["rabbitmq", "performance", "architecture", "delayed-messages"]
    },
    {
      "id": "missing-delay-validation",
      "name": "Not validating delay values before publishing",
      "problem": "Passing unvalidated metadata.delay directly to message broker without type/range checks",
      "why_bad": [
        "Runtime errors from invalid types (string, object, null)",
        "Unexpected behavior from negative delays",
        "NaN or undefined causes broker errors",
        "No fallback strategy for invalid input"
      ],
      "better_approach": "Validate delay is number >= 0, fall back to immediate delivery for invalid values",
      "tags": ["validation", "type-safety", "error-handling", "delayed-messages"]
    },
    {
      "id": "insufficient-edge-case-testing",
      "name": "Testing only happy path for optional numeric fields",
      "problem": "Only testing valid delay values without covering invalid input scenarios",
      "why_bad": [
        "Production failures from unexpected user input",
        "No visibility into how code handles edge cases",
        "Regressions go undetected during refactoring",
        "Unclear fallback behavior"
      ],
      "better_approach": "Test 8+ edge cases: negative, zero, string, null, undefined, NaN, object, Infinity",
      "tags": ["testing", "edge-cases", "validation", "robustness"]
    },
    {
      "id": "read-modify-write-retry-counter",
      "name": "Using read-modify-write pattern for retry counters",
      "problem": "Reading retry count, incrementing it, then writing back in separate operations",
      "why_bad": [
        "Race condition: Multiple instances can read same value",
        "Lost updates: Last write wins, losing other increments",
        "Incorrect retry counts lead to wrong behavior",
        "Silent corruption in distributed systems"
      ],
      "better_approach": "Use atomic database increment operations (SQL: retry_count + 1, MongoDB: $inc)",
      "example": {
        "wrong": "const msg = await repo.findOne(id); msg.retryCount += 1; await repo.save(msg);",
        "correct": "await repo.update(id, { retryCount: () => 'retry_count + 1' });"
      },
      "tags": ["concurrency", "race-condition", "atomic-operations", "anti-pattern"]
    },
    {
      "id": "immediate-retry-without-backoff",
      "name": "Retrying failed operations immediately without delay",
      "problem": "Retrying failed messages immediately after failure",
      "why_bad": [
        "Retry storms overload already-failing systems",
        "Wastes resources on operations likely to fail again",
        "Cascading failures spread to dependent systems",
        "No time for transient issues to resolve"
      ],
      "better_approach": "Use exponential backoff with jitter and scheduledAt field",
      "tags": ["retry", "backoff", "performance", "anti-pattern"]
    }
  ],
  "metadata": {
    "total_skills": 18,
    "total_patterns": 5,
    "total_anti_patterns": 10,
    "last_updated": "2026-01-12T00:00:00Z",
    "created_at": "2026-01-05T00:00:00Z",
    "last_task": "AIRIS-63: feat(inbox): add retry mechanism with exponential backoff and feat(outbox): implement exponential backoff for failed messages"
  }
}
